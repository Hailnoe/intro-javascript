# Data Types

Remember, underneath it all the computer is encoding data as sequences of `1`s and `0`s, which we call a **binary sequence**. We call each individual `1` or `0` a **bit** (short for **b**inary dig**it**). These sequences have no more meaning than if I wrote down a random sequence of `a` and `b` characters on a piece of paper.

What makes these sequences useful is our ability to *interpret* them according to different rules. Each way of interpreting a sequence is called a "data type".

For example, we might say "Given an 8-bit binary sequence, we can use the [binary numbering system][wiki-binary-number] to interpret it as a non-negative integer between 0 and 255." Some languages support this data type explicitly and would call it an "8-bit unsigned integer".

[wiki-binary-number]: https://en.wikipedia.org/wiki/Binary_number
